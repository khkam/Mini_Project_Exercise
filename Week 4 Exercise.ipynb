{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79762474",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81d6fd6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "# Python 3.7 is required\n",
    "assert sys.version_info >= (3,7)\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "# For reproducibility,\n",
    "np.random.seed(99)\n",
    "\n",
    "# Make sure that optimization is enabled\n",
    "if not cv.useOptimized():\n",
    "    cv.setUseOptimized(True)\n",
    "\n",
    "cv.useOptimized()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883232e2",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011bf055",
   "metadata": {},
   "source": [
    "## First Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4dd29a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv.imread(\"dog.jfif\") #first image\n",
    "img2 = cv.imread(\"dog.jfif\",0) #second image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcddb861",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.imshow('dog',img1)\n",
    "cv.imshow('gray dog',img2)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bceed7f4",
   "metadata": {},
   "source": [
    "## Second Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82200f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv.imread(\"flower.jfif\") #first image\n",
    "img1_2dimension = cv.cvtColor(img1,cv.COLOR_BGR2GRAY) #convert first image to gray image with 2 dimensions\n",
    "\n",
    "img2 = cv.cvtColor(img1_2dimension,cv.COLOR_GRAY2BGR) #gray image with 3 dimensions\n",
    "\n",
    "vertical_combine = np.vstack((img1,img2)) #stack vertically\n",
    "\n",
    "cv.imshow('multiple image',vertical_combine)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee789db",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92c87767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1920, 1080, 3)\n"
     ]
    }
   ],
   "source": [
    "# Create a VideoCapture object\n",
    "cap = cv.VideoCapture('img_pexels.mp4')\n",
    "\n",
    "ret, frame = cap.read()\n",
    "print (frame.shape) #know the original frame size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c15d97d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fourcc = cv.VideoWriter_fourcc('M', 'J', 'P', 'G')\n",
    "out = cv.VideoWriter('smaller_img_pexels.mp4',fourcc, 30.0,(1080,500))\n",
    "\n",
    "# Check if the object has been created successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Unable to create video\")\n",
    "\n",
    "# Read until the video is completed.\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if ret == True:\n",
    "        resize_frame = cv.resize(frame,(1080,500),fx = 0,fy = 0) #convert it to a new frame size\n",
    "        out.write(resize_frame)\n",
    "    else:\n",
    "    # if frame is read then ret is True\n",
    "        print(\"Can't receive frame.\")\n",
    "        break\n",
    "    \n",
    "    cv.imshow('resized frame', resize_frame)\n",
    "    # Press Esc key to exit (27 is ASCII code for Esc). cv.waitKey() returns 32 bit integer values. You can find the ASCII table\n",
    "    # on this URL: https://theasciicode.com.ar/\n",
    "    if cv.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "# destroy the constructor\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e58bbf",
   "metadata": {},
   "source": [
    "# Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62864c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#random noise with 3 dimensions array\n",
    "random_noise = np.random.randint(low = 0,high = 255, size= (500,500,3)\n",
    "                                 ,dtype = np.uint8)\n",
    "\n",
    "cv.imshow(\"random noise image\", random_noise)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7cdd9d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert it to a grayscale image\n",
    "gray_noise = cv.cvtColor(random_noise,cv.COLOR_BGR2GRAY)\n",
    "\n",
    "cv.imshow(\"gray noise image\", gray_noise)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81bf952",
   "metadata": {},
   "source": [
    "# Extract the ROI of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55b4bc79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(183, 275, 3)\n"
     ]
    }
   ],
   "source": [
    "img = cv.imread('flower.jfif')\n",
    "print (img.shape) #know the original size of image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5962bf94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(40 - 120) height,(90, 175)\n",
    "flower = img[40:120,90:175]\n",
    "cv.imshow('ROI of flower',flower)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606f284a",
   "metadata": {},
   "source": [
    "# Enlarge image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e8e3698",
   "metadata": {},
   "outputs": [],
   "source": [
    "#enlarge image with different interpolation methods\n",
    "img = cv.imread(\"dog.jfif\")\n",
    "\n",
    "#Resize: linear,cubic and nearest\n",
    "img_large_linear = cv.resize(img, None, fx = 2.5, fy = 2.5, interpolation = cv.INTER_LINEAR)\n",
    "img_large_cubic = cv.resize(img, None, fx = 2.5, fy = 2.5, interpolation = cv.INTER_CUBIC)\n",
    "img_large_nearest = cv.resize(img, None, fx = 2.5, fy = 2.5, interpolation = cv.INTER_NEAREST)\n",
    "\n",
    "cv.imshow('linear',img_large_linear)\n",
    "cv.imshow('cubic',img_large_cubic)\n",
    "cv.imshow('nearest',img_large_nearest)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2a5bed",
   "metadata": {},
   "source": [
    "The differences is: resulting image from nearest neighbor interpolation is more jagged on the boundary of object (dog)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
