{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31b318ec",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad0b2ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5f068d",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48a3f291",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('dog1.jfif', 0)\n",
    "\n",
    "eq1 = cv.equalizeHist(img)\n",
    "eq2 = cv.equalizeHist(eq1)\n",
    "\n",
    "cv.imshow('result', np.hstack((img, eq1, eq2)))\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d72f9a",
   "metadata": {},
   "source": [
    "Comment: There is no difference between first and second output image since it is already equalized. It can't be equalized anymore."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575d18fa",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4184c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('electronic.jfif', 0)\n",
    "\n",
    "sobelx = cv.Sobel(img, cv.CV_64F, 1,0, ksize = 1)\n",
    "sobely = cv.Sobel(img, cv.CV_64F, 0,1, ksize = 1)\n",
    "\n",
    "grad_mag_L2 = cv.magnitude(sobelx,sobely)\n",
    "grad_mag_L2 = cv.convertScaleAbs(grad_mag_L2)\n",
    "\n",
    "cv.imshow(\"result\", np.hstack((img,grad_mag_L2)))\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2c6c1f",
   "metadata": {},
   "source": [
    "Kernel size 1 is chosen as there is less white line (noises) in the images compared to kernel size 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "daccc014",
   "metadata": {},
   "outputs": [],
   "source": [
    "blur = cv.GaussianBlur(img, (5,5), 0)\n",
    "\n",
    "sobelx = cv.Sobel(blur, cv.CV_64F, 1,0, ksize = 1)\n",
    "sobely = cv.Sobel(blur, cv.CV_64F, 0,1, ksize = 1)\n",
    "\n",
    "blur_grad_mag_L2 = cv.magnitude(sobelx,sobely)\n",
    "blur_grad_mag_L2 = cv.convertScaleAbs(blur_grad_mag_L2)\n",
    "\n",
    "cv.imshow(\"result\", np.hstack((grad_mag_L2,blur_grad_mag_L2)))\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0759dca1",
   "metadata": {},
   "source": [
    "The noises become less obvious after gaussian blur is applied. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "070e17ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "blur = cv.GaussianBlur(img, (5,5), 0)\n",
    "laplacian = cv.Laplacian(blur,cv.CV_64F, ksize =3)\n",
    "\n",
    "laplacian_8u = cv.convertScaleAbs(laplacian)\n",
    "\n",
    "cv.imshow(\"result\", np.hstack((grad_mag_L2, blur_grad_mag_L2, laplacian_8u)))\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c642a940",
   "metadata": {},
   "source": [
    "The most optimal image processing pathway is apply gaussian filter, then apply sobel edge detection as the image processed is obvious with the edge and the noise produced is the least among three of them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f450b04f",
   "metadata": {},
   "source": [
    "# Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5698910d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('pineapple.jfif', 0)\n",
    "img_blur = cv.GaussianBlur(img, (5,5), 0)\n",
    "\n",
    "# Sobel\n",
    "sobelx = cv.Sobel(img_blur, cv.CV_64F, 1,0, ksize = 3)\n",
    "sobely = cv.Sobel(img_blur, cv.CV_64F, 0,1, ksize = 3)\n",
    "blur_grad_mag_L2 = cv.magnitude(sobelx,sobely)\n",
    "blur_grad_mag_L2 = cv.convertScaleAbs(blur_grad_mag_L2)\n",
    "\n",
    "#laplacian\n",
    "laplacian_blur = cv.Laplacian(img_blur, cv.CV_64F, ksize = 3)\n",
    "laplacian_blur = np.uint8(np.absolute(laplacian_blur))\n",
    "\n",
    "#Prewitt\n",
    "kernelx = np.array([[1,1,1],[0,0,0],[-1,-1,-1]])\n",
    "kernely = np.array([[-1,0,1],[-1,0,1],[-1,0,1]])\n",
    "img_prewittx = cv.filter2D(img_blur, -1, kernelx)\n",
    "img_prewitty = cv.filter2D(img_blur, -1, kernely)\n",
    "img_comb_prewitt = (img_prewittx + img_prewitty)\n",
    "\n",
    "#Scharr Derivatives\n",
    "scharr_X = cv.Scharr(img_blur, cv.CV_64F, 1, 0) \n",
    "scharr_X_abs = np.uint8(np.absolute(scharr_X)) \n",
    "scharr_Y = cv.Scharr(img_blur, cv.CV_64F, 0, 1) \n",
    "scharr_Y_abs = np.uint8(np.absolute(scharr_Y)) \n",
    "scharr_XY_combined = cv.bitwise_or(scharr_Y_abs,scharr_X_abs) \n",
    "\n",
    "#Canny operators\n",
    "edges = cv.Canny(img_blur, 100, 200)\n",
    "\n",
    "# all output\n",
    "cv.imshow(\"result\", np.hstack((blur_grad_mag_L2,laplacian_blur, img_comb_prewitt, scharr_XY_combined, edges)))\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03af6cf",
   "metadata": {},
   "source": [
    "- Sobel: The edge detected is spreaded out.\n",
    "- Laplacian: Can clearly see the edge but its too small.\n",
    "- Prewitt: The edge detected is blurry but can see the shape of pineapple.\n",
    "- Scharr Derivatives: All the edges in image is detected and its quite complicated.\n",
    "- Canny operators: The cleanest edge detected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ed52c6",
   "metadata": {},
   "source": [
    "# Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "305f77c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('electronic.jfif')\n",
    "img_gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY) \n",
    "\n",
    "img = cv.GaussianBlur(img_gray, (5,5), 0)\n",
    "ret, thresh = cv.threshold(img_gray, 180, 255, cv.THRESH_BINARY)\n",
    "\n",
    "contours, _ = cv.findContours(thresh, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "for i in contours:\n",
    "    area = cv.contourArea(i)\n",
    "    if area >= 1000:\n",
    "        cnt = i\n",
    "        x, y, w, h = cv.boundingRect(cnt)\n",
    "        cv.rectangle(img_gray, (x,y), (x+w, y+h), (0, 255, 255), 2)\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "cv.imshow('result', img)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85159ecf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
